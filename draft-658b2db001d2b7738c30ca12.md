---
title: "Installing LangChain, LangSmith, LangeServe, and LangGraph."
slug: installing-langchain-langsmith-langeserve-and-langgraph

---

# TL;DR.

\[pending\]

> **Attributions:**
> 
> [https://python.langchain.com/](https://python.langchain.com/)***↗***

# An Introduction.

\[pending\]

# The Big Picture.

\[pending\]

# Prerequisites.

* A Debian-based Linux distro (I use Ubuntu),
    
* [Miniconda](https://solodev.app/installing-miniconda).
    

# Updating my Base System.

* From the (base) terminal, I update my (base) system:
    

```python
sudo apt clean && \
sudo apt update && \
sudo apt dist-upgrade -y && \
sudo apt --fix-broken install && \
sudo apt autoclean && \
sudo apt autoremove -y
```

> NOTE: The Ollama LLM manager is already installed on my (base) system.

# What is Anaconda and Miniconda?

Python projects can run in virtual environments. These isolated spaces are used to manage project dependencies. Different versions of the same package can run in different environments while avoiding version conflicts.

venv is a built-in Python 3.3+ module that runs virtual environments. Anaconda is a Python and R distribution for scientific computing that includes the `conda` package manager. Miniconda is a small, free, bootstrap version of Anaconda that also includes the `conda` package manager, Python, and other packages that are required or useful (like pip and zlib).

[http://www.anaconda.com/](http://www.anaconda.com/)***↗,***

[https://docs.anaconda.com/free/miniconda/index.html](https://docs.anaconda.com/free/miniconda/index.html)***↗, and***

[https://solodev.app/installing-miniconda](https://solodev.app/installing-miniconda).

I ensure [Miniconda is installed](https://solodev.app/installing-miniconda) (`conda -V`) before continuing with this post.

## Creating a Miniconda Environment.

* From the (base) terminal, I use the `conda` command to display a `list` of Miniconda `env`ironments:
    

```bash
conda env list
```

> NOTE: [Install Miniconda](https://solodev.app/installing-miniconda) to successfully run this command.

* I use `conda` to `create`, and `activate`, a new environment named (-n) (LangChain):
    

```bash
conda create -n LangChain python=3.11 -y && conda activate LangChain
```

> NOTE: This command creates the (LangChain) environment, then activates the (LangChain) environment.

## Creating the LangChain Home Directory.

> NOTE: I will now define the home directory in the environment directory.

* I create the LangChain home directory:
    

```bash
mkdir ~/LangChain
```

* I make new directories within the (LangChain) environment:
    

```bash
mkdir -p ~/miniconda3/envs/LangChain/etc/conda/activate.d
```

* I use the Nano text editor to create the `set_working_directory.sh` shell script:
    

```bash
sudo nano ~/miniconda3/envs/LangChain/etc/conda/activate.d/set_working_directory.sh
```

* I copy the following, paste (CTRL + SHIFT + V) it to the `set_working_directory.sh` script, save (CTRL + S) the changes, and exit (CTRL + X) Nano:
    

```bash
cd ~/LangChain
```

* I activate the (base) environment:
    

```bash
conda activate
```

* I activate the (LangChain) environment:
    

```bash
conda activate LangChain
```

> NOTE: I should now, by default, be in the `~/LangChain` home directory.

# What is Ollama?

Ollama is a tool that is used to download, set up, and run large language models on a local PC. It lets me use powerful models like Llama 2 and Mistral on my personal computer. Ollama natively runs on Linux, macOS, and Windows.

[https://ollama.com/](https://ollama.com/%E2%86%97)↗.

I ensure [Ollama is installed](https://solodev.app/installing-ollama) (`ollama -v`) before continuing with this post.

## Running the Llama2 Language Model.

* From a *second* (base) terminal, I activate the Ollama environment:
    

```bash
conda activate Ollama
```

> NOTE: [Install Ollama](https://solodev.app/installing-ollama) to successfully run this command.

* I use Ollama to run Llama2:
    

```bash
ollama run llama2
```

# What is LiteLLM?

LiteLLM provides LLMs with IP addresses. It is a unified interface that calls 100+ LLMs using the same Input/Output format, supporting OpenAI, Huggingface, Anthropic, vLLM, Cohere, and even custom LLM API services.

[https://litellm.ai/↗](https://litellm.ai/%E2%86%97).

I ensure [LiteLLM is installed](https://solodev.app/installing-litellm) (pending) before continuing with this post.

## Running Llama2 with LiteLLM.

* From a *third* (base) terminal, I activate the LiteLLM environment:
    

```bash
conda activate LiteLLM
```

> NOTE: [Install LiteLLM](https://solodev.app/installing-litellm) to successfully run this command.

* I use LiteLLM to run Llama2:
    

```bash
litellm --model ollama/llama2
```

# What is LangChain, LangSmith, LangeServe, and LangGraph?

LangChain is a Python and JavaScript library that helps me build language model applications. It uses these models to help with tasks like answering questions, creating text, or performing other tasks.

LangSmith is a tool for creating professional LLM applications. It helps me debug, test, check, and keep an eye on chains, and smart agents, made with any LLM framework, and is designed to work smoothly with LangChain.

LangeServe is a platform for deploying and maintaining my LLM applications. It helps me turn any LangChain runnable, or chain, into a REST API, making my LangChain projects ready for real-world use.

LangGraph is a tool for creating complex applications with LLMs that involve multiple parts working together. It is designed to work with LangChain and adds new features to the LangChain Expression Language, helping me manage several chains (or parts) through many steps in a loop.

[https://python.langchain.com/docs/get\_started/introduction](https://python.langchain.com/docs/get_started/introduction)↗,

[https://docs.smith.langchain.com](https://docs.smith.langchain.com)↗,

[https://www.langchain.com/langserve](https://www.langchain.com/langserve)↗, and

[https://python.langchain.com/docs/langgraph](https://python.langchain.com/docs/langgraph)↗.

I ensure these LangChain tools are installed (pending) before continuing with this post.

## Installing the LangChain Tools.

* Back in the *first* (base) terminal, I install `langchain`, `langsmith`, and `langserve`:
    

```bash
pip install langchain langsmith "langserve[all]" langgraph
```

## Testing the LangChain Installation.

\[pending\]

# The Results.

\[pending\]

# In Conclusion.

\[pending\]