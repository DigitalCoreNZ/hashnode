---
title: "4 of 5: Making Embeddings with Nomic."
slug: 4-of-5-making-embeddings-with-nomic
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1716798584415/8b732990-00f8-45d3-8361-9dddf908ae68.png

---

JavaScript Scraping | Scrapy | ScrapeGraphAI | Nomic | Embeddings & LLMs

# TL;DR.

\[pending\]

> **Attributions:**
> 
> [https://docs.anaconda.com/free/miniconda/index.html](https://docs.anaconda.com/free/miniconda/index.html)***↗.***

# An Introduction.

\[pending\]

# The Big Picture.

Nomic Embed is an embedding model. It supports BERT and Nomic-BERT language representations. There are other popular embedding models and, as they grow in complexity, we need new ways to evaluate them beyond traditional benchmarks. Comparing the vector spaces of Nomic Embed and OpenAI Ada (using a sample from English Wikipedia) shows significant differences in how they handle disambiguation pages. Nomic Embed groups these pages closely together, whereas OpenAI Ada spreads them across different areas. This highlights the importance of developing new evaluation methods to understand the subtle ways embedding models organize their data, and the effects these differences have on db metrics, e.g. performance, efficiency, size, etc.

# Prerequisites.

* A Debian-based Linux distro (I use Ubuntu),
    
* [Miniconda](https://solodev.app/installing-miniconda).
    

# Updating my Base System.

* From the (base) terminal, I update my (base) system:
    

```python
sudo apt clean && \
sudo apt update && \
sudo apt dist-upgrade -y && \
sudo apt --fix-broken install && \
sudo apt autoclean && \
sudo apt autoremove -y
```

> NOTE: The Ollama LLM manager is already installed on my (base) system.

# What is Anaconda and Miniconda?

Python projects can run in virtual environments. These isolated spaces are used to manage project dependencies. Different versions of the same package can run in different environments while avoiding version conflicts.

venv is a built-in Python 3.3+ module that runs virtual environments. Anaconda is a Python and R distribution for scientific computing that includes the conda package manager. Miniconda is a small, free, bootstrap version of Anaconda that also includes the conda package manager, Python, and other packages that are required or useful (like pip and zlib).

[http://www.anaconda.com/↗](http://www.anaconda.com/%E2%86%97),

[https://docs.anaconda.com/free/miniconda/index.html↗](https://docs.anaconda.com/free/miniconda/index.html%E2%86%97), and

[https://solodev.app/installing-miniconda](https://solodev.app/installing-miniconda).

I ensure Miniconda is installed (conda -V) before continuing with this post.

## Creating a Miniconda Environment.

* I use the `conda` command to display a `list` of Miniconda `env`ironments:
    

```bash
conda env list
```

* I use `conda` to `create`, and `activate`, a new environment named (-n) (Default):
    

```bash
conda create -n Default python=3.11 -y && conda activate Default
```

> NOTE: This command creates the (Default) environment, then activates the (Default) environment.

## Creating the `Default` Home Directory.

> NOTE: I will now define the home directory in the environment directory.

* I create the `Default` home directory:
    

```bash
mkdir ~/Default
```

* I make new directories within the (Default) environment:
    

```bash
mkdir -p ~/miniconda3/envs/Default/etc/conda/activate.d
```

* I use the Nano text editor to create the `set_working_directory.sh` shell script:
    

```bash
sudo nano ~/miniconda3/envs/Default/etc/conda/activate.d/set_working_directory.sh
```

* I copy the following, paste (CTRL + SHIFT + V) it to the `set_working_directory.sh` script, save (CTRL + S) the changes, and exit (CTRL + X) Nano:
    

```bash
cd ~/Default
```

* I activate the (base) environment:
    

```bash
conda activate
```

* I activate the (Default) environment:
    

```bash
conda activate Default
```

> NOTE: I should now, by default, be in the `~/Default` home directory.

# What is Nomic Embed?

Nomic Embed is a text embedding model that is open source and fully reproducible. It can process text up to 8,192 characters long and uses openly available, curated data for training. Text embeddings are crucial for modern NLP (natural language processing) applications that offer enhanced search, or mechanisms that generate responses for LLMs (large language models). Embeddings models turn text into vectors, which are then used in various tasks such as clustering for visualization, classifying information, and retrieving data.

[https://blog.nomic.ai/posts/nomic-embed-text-v1](https://blog.nomic.ai/posts/nomic-embed-text-v1%E2%86%97)↗.

## Installing Nomic Embed.

* I use Ollama to pull the Nomic Embed model:
    

```bash
ollama pull nomic-embed-text
```

# The Results.

\[pending\]

# In Conclusion.

\[pending\]

\[hash tags\]

[Scraping URLs](https://solodev.app/1-of-5-scraping-website-urls) | [Scraping Tutorial](https://solodev.app/2-of-5-scraping-tutorial-for-the-scrapy-tool) | Scraping Data | Making Embeddings | Using Embeddings